{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fj798spImN3N"
   },
   "source": [
    "\n",
    "\n",
    "1. PyTorch Basics\n",
    "    - Toy example with PyTorch\n",
    "2. Image Classification with PyTorch\n",
    "    - Implement a simple MLP network for image classification\n",
    "    - Implement a convolutional network for image classification\n",
    "    - Experiment with different numbers of layers and optimizers\n",
    "    - Push the performance of your CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfhW52lsmN3R"
   },
   "source": [
    "In this homework, you would need to use **Python 3.6+** along with the following packages:\n",
    "```\n",
    "1. pytorch 1.2\n",
    "2. torchvision\n",
    "3. numpy\n",
    "4. matplotlib\n",
    "```\n",
    "To install pytorch, please follow the instructions on the [Official website](https://pytorch.org/). In addition, the [official document](https://pytorch.org/docs/stable/) could be very helpful when you want to find certain functionalities. \n",
    "\n",
    "You can also consider to use Google Colab, where PyTorch has been installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhuJCQ00mN3S"
   },
   "source": [
    "# Section 1. PyTorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbpkNgExmN3U"
   },
   "source": [
    "Simply put, PyTorch is a **Tensor** library like Numpy. These two libraries similarly provide useful and efficient APIs for you to deal with your tensor data. What really differentiate PyTorch from Numpy are the following two features:\n",
    "1. Numerical operations that can **run on GPUs** (more than 10x speedup)\n",
    "2. Automatic differentiation for building and training neural networks\n",
    "\n",
    "In this section, we will walk through some simple example, and see how the automatic differentiation functionality can make your life much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQQXAQv5mN3V"
   },
   "source": [
    "### To select GPU in Google Colab:\n",
    "- go to **Edit -> Notebook settings -> Hardware accelerator -> GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7wX-pIFmN3X"
   },
   "outputs": [],
   "source": [
    "import torch # import pytorch.\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSWC55uDmN3f"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "#print(torch.cuda.get_device_name(0)) # Check GPU Device name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gecUPQG9mN3n"
   },
   "source": [
    "## 1.1. Automatic Differentiation\n",
    "Gradient descent is the driving force of the deep learning field. In the lectures and assignment 1, we learned how to derive the gradient for a given function, and implement methods for calculating and performing gradient descents. We also see how we can manually implement the backward and forward functions for the simple NN example. While implementing these functions may not be a big deal for a small network, it may get very nasty when we want to build something with tens of hundreds of layers.\n",
    "\n",
    "In PyTorch (as well as other major deep learning libraries), we can use autograd ([automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)) to handle the tedious computation of backward passes. When doing forward passes with autograd, we are essentially defining a **computational graph**, while the nodes in the graph are **tensors**, the edges are the functions that produce output tensors (e.g. ReLU, Linear, Convolutional Layer) given the input tensors. To do backpropagation, we can simply backtrack through this graph to compute gradients. \n",
    "\n",
    "This may sound a little bit abstract, so let's take a look at the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fci1Bw9_mN3o",
    "outputId": "5ce1aa06-8d73-4c54-e9fc-b15ff0d77211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4944,  1.4592],\n",
      "        [ 0.4258, -0.0716]], requires_grad=True)\n",
      "tensor([[-1.2824, -0.2203],\n",
      "        [-0.4580, -0.4354]], requires_grad=True)\n",
      "tensor([[-1.7768,  1.2390],\n",
      "        [-0.0322, -0.5070]], grad_fn=<AddBackward0>)\n",
      "tensor(-1.0771, grad_fn=<SumBackward0>)\n",
      "tensor(-11.0771, grad_fn=<SubBackward0>)\n",
      "-----gradient-----\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "target = 10.\n",
    "\n",
    "# create a matrix of size 2x2. Each with value draws from standard normal distribution.\n",
    "x = torch.randn(2, 2, requires_grad=True) \n",
    "y = torch.randn(2, 2, requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "b = a.sum()\n",
    "loss = b - target\n",
    "\n",
    "# print out each tensor:\n",
    "print(x)\n",
    "print(y)\n",
    "print(a)\n",
    "print(b)\n",
    "print(loss)\n",
    "\n",
    "print(\"-----gradient-----\")\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa58EGucmN3w"
   },
   "source": [
    "In the above example, we have seen a few things:\n",
    "1. `requires_grad` flag: If false, we can safely exclude this tensor (and its subgraph) from gradient computation and therefore increase efficiency.\n",
    "2. `grad_fn`: we can see that once an operation is done to a tensor, the output tensor is bound to a backward function associated to the operation. In this case, we have Add, Sum, and Sub.\n",
    "\n",
    "However, even if we set `requires_grad=True`, we still don't have gradient for `x` and `y`. This is because that we haven't performed the backpropagation yet. So let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_ECvgoTmN3x",
    "outputId": "f5cad53e-9d56-4f4d-f13e-a74025150369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----gradient-----\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# perform backpropagation from this \"node\"\n",
    "loss.backward()\n",
    "print('-----gradient-----')\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCjGoYvqmN34"
   },
   "source": [
    "Great, seems like we can perform gradient descent without writing backwards function! Now, let's see a simple toy example on how we can fit some weights `w1` and `w2` with random input `x` and target `y`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1XmyMqqmN35",
    "outputId": "60d2cb0d-17ca-427a-e21a-9183c2b29453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 99: 341.04962158203125\n",
      "iteration 199: 1.6489198207855225\n",
      "iteration 299: 0.0150656308978796\n",
      "iteration 399: 0.00035873911110684276\n",
      "iteration 499: 5.391986996983178e-05\n"
     ]
    }
   ],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Tensors during the backward pass.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Tensors; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(f'iteration {t}: {loss.item()}')\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.  (because we don't need the gradient for the operation \n",
    "    # learning_rate * w1.grad)\n",
    "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
    "    # Recall that tensor.data gives a tensor that shares the storage with\n",
    "    # tensor, but doesn't track history.\n",
    "    # You can also use torch.optim.SGD to achieve this.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjAwXuQOmN4A"
   },
   "source": [
    "## 1.2. `nn` Module\n",
    "Computational graphs and autograd are a very powerful paradigm for defining complex operators and automatically taking derivatives; however for large neural networks raw autograd can be a bit too low-level.\n",
    "\n",
    "When building neural networks we frequently think of arranging the computation into layers, some of which have learnable parameters which will be optimized during learning.\n",
    "\n",
    "In PyTorch, the nn package serves this purpose. The nn package defines a set of Modules, which are roughly equivalent to neural network layers. A Module receives input Tensors and computes output Tensors, but may also hold internal state such as Tensors containing learnable parameters. The nn package also defines a set of useful loss functions that are commonly used when training neural networks.\n",
    "\n",
    "Now, let's see how our simple NN could be implemented using the nn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyow0LgUmN4C"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(f'iteration {t}: {loss.item()}')\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gneQKfwxmN4I"
   },
   "source": [
    "So far, we have been updating the model parameters manually with `torch.no_grad()`. However, if we want to use optimization algorithms other than SGD, it might get a bit nasty to do it manually. Instead of manually doing this, we can use `optim` pacakge to help optimize our model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIzAkrdZmN4J"
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H, D_out),\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. \n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(f'iteration {t}: {loss.item()}')\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymuIiWcGmN4P"
   },
   "source": [
    "Sometimes you will want to specify models that are more complex than a sequence of existing Modules; for these cases you can define your own Modules by subclassing nn.Module and defining a forward which receives input Tensors and produces output Tensors using other modules or other autograd operations on Tensors.\n",
    "\n",
    "For example, we can implement our 2-layer simple NN as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgHoYfcUmN4Q"
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(f'iteration {t}: {loss.item()}')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaG5_yoSmN4U"
   },
   "source": [
    "## 1.3. Warm-up: Two-moon datasets \n",
    "Now, let's use PyTorch to solve some synthetic datasets. In previous assignment, we have to write some codes to create training batches. Again, this can also be done with PyTorch `DataLoader`. The `DataLoader` utilizes parallel workers to read and prepare batches for you, which can greatly speedup the code when your time bottleneck is on file I/O.\n",
    "\n",
    "Here, we show a simple example that can create a dataloader from numpy data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcsJ2yuwmN4V"
   },
   "source": [
    "### Setup for Google Colab (Skip for Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfBCiLZcmN4V"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pusGnrzAmN4Z"
   },
   "outputs": [],
   "source": [
    "# Find path to your data folder in drive and enter for \"path_to_dataset\"\n",
    "#path_to_dataset = '/content/drive/My Drive/DL_Fall_2020/Assignment_2/data'\n",
    "path_to_dataset ='C:/Users/sharm/Desktop/Niket_Documents/courses/Deep Learning/Assingments/Assingment 2/HW2/data'\n",
    "# For Jupyter notebook give path from your local PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITOohGZOmN4e",
    "outputId": "f09c40d2-3799-487c-ac4e-162b543e337f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = np.loadtxt(path_to_dataset + '/X1_train.csv', delimiter=',')\n",
    "X_test = np.loadtxt(path_to_dataset + '/X1_test.csv', delimiter=',')\n",
    "y_train = np.loadtxt(path_to_dataset + '/y1_train.csv', delimiter=',')\n",
    "y_test = np.loadtxt(path_to_dataset + '/y1_test.csv', delimiter=',')\n",
    "\n",
    "# Plot it to see why is it called two-moon dataset\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWjuWw22mN4k"
   },
   "source": [
    "Now, let's create a PyTorch `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVd6KjQNmN4l"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "batch_size = 64 # mini-batch size\n",
    "num_workers = 4 # how many parallel workers are we gonna use for reading data\n",
    "shuffle = True # shuffle the dataset\n",
    "\n",
    "# Convert numpy array import torch tensor\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train.reshape(-1, 1))\n",
    "y_test = torch.LongTensor(y_test.reshape(-1, 1))\n",
    "\n",
    "# First, create a dataset from torch tensor. A dataset define how to read data\n",
    "# and process data for creating mini-batches.\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                          num_workers=num_workers, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSE9kmZ1mN4r",
    "outputId": "3cd7e493-73be-42d3-aeba-171e3f5c0b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([700, 2])\n",
      "torch.Size([700, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZOXZ9nnmN4x"
   },
   "source": [
    "Below, we provide a simple example on how to train your model with this dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__-VgewxmN4y",
    "outputId": "fc505466-3ec0-417b-e23c-1ce94e243d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoh 0: 6.804924130439758\n",
      "Epcoh 1: 4.205340951681137\n",
      "Epcoh 2: 3.1848054230213165\n",
      "Epcoh 3: 2.9674482494592667\n",
      "Epcoh 4: 2.9060702472925186\n"
     ]
    }
   ],
   "source": [
    "epoch = 5 # an epoch means looping through all the data in the datasets\n",
    "lr = 1e-1\n",
    "\n",
    "# create a simple model that is probably not gonna work well\n",
    "model = nn.Linear(X_train.size(1), 1)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for e in range(epoch):\n",
    "    loss_epoch = 0\n",
    "    # loop through train loader to get x and y\n",
    "    for x, y in train_loader:\n",
    "        optim.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        # !!WARNING!!\n",
    "        # THIS IS A CLASSIFICATION TASK, SO YOU SHOULD NOT\n",
    "        # USE THIS LOSS FUNCTION. \n",
    "        loss = (y_pred - y.float()).abs().mean()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loss_epoch += loss.item()\n",
    "    print(f'Epcoh {e}: {loss_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxDE84vqmN43"
   },
   "source": [
    "### 1.3.1 Your Simple NN\n",
    "Now, it is time for you to implement your own model for this classification task. Your job here is to:\n",
    "1. Complete the SimpleNN class. It should be a 2- or 3-layer NN with proper non-linearity.\n",
    "2. Train your model with SGD optimizer.\n",
    "3. Tune your model a bit so you can achieve at least 80% accuracy on training set.\n",
    "Hint: you might want to look up `nn.ReLU`, `nn.Sigmoid`, `nn.BCELoss` in the [official document](https://pytorch.org/docs/stable/). You are allowed to freely pick the hyperparameters of your model.\n",
    "4. **Please note this is a binary classification problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_JtMDBNmN44"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,D_in, H, D_out):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct your small feedforward NN here.                                    #\n",
    "        ################################################################################\n",
    "        #D_in = X_train.shape[1]\n",
    "        #D_out = np.max(y_train) + 1\n",
    "        #H = 100\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # feed the input to your network, and output the predictions.                  #\n",
    "        ################################################################################\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCOscHmMmN48",
    "outputId": "1c517175-60d3-419e-ec61-23d6a185efb7"
   },
   "outputs": [],
   "source": [
    "epoch = 10 # an epoch means looping through all the data in the datasets\n",
    "lr = 1e-1\n",
    "\n",
    "# create a simple model that is probably not gonna work well\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Initialize your model and SGD optimizer here.  \n",
    "N, D_in, H, D_out = 64, 700, 100, 2\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = SimpleNN(D_in, H, D_out)\n",
    "\n",
    "#\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    loss_epoch = 0  # record accmulative loss for each epoch\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Loop through the dataloader and train your model with nn.BCELoss.            #\n",
    "    ################################################################################\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss_epoch = criterion(y_pred, y)\n",
    "    if e % 10 == 9:\n",
    "        print(f'iteration {t}: {loss.item()}')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()   \n",
    "    \n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6PvWtAjmN5B"
   },
   "outputs": [],
   "source": [
    "# helper function for computing accuracy\n",
    "def get_acc(pred, y):\n",
    "    pred = pred.float()\n",
    "    y = y.float()\n",
    "    return (y==pred).sum().float()/y.size(0)*100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueRrynd3mN5G"
   },
   "source": [
    "Evaluate your accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS51XbyjmN5G"
   },
   "outputs": [],
   "source": [
    "y_pred = (model(X_train) > 0.5)\n",
    "train_acc = get_acc(y_pred, y_train)\n",
    "\n",
    "y_pred = (model(X_test) > 0.5)\n",
    "test_acc = get_acc(y_pred, y_test)\n",
    "print(f'Training accuracy: {train_acc}, Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhX0lH3jmN5L"
   },
   "source": [
    "# Section 2. Image Classification with CNN \n",
    "Now, we are back to the image classification problem. In this section, our goal is to, again, train models on CIFAR-10 to perform image classification. Your tasks here are to:\n",
    "1. Build and Train a simple feed-forward Neural Network (consists of only nn.Linear layer with activation function) for the classification task\n",
    "2. Build and Train a **Convolutional** Neural Network (CNN) for the classification task\n",
    "3. Try different settings for training your CNN\n",
    "4. Reproduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMqRRDzmN5M"
   },
   "source": [
    "In the following cell, we provide the code for creating a CIFAR10 dataloader. As you can see, PyTorch's `torchvision` package actually has an interface for the CIFAR10 dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "274c0e74340045a881b4aa8d13b1e1a2",
      "bb452709a08843919787948ab5171fc0",
      "ca16990a99cb445fbf35b516d9deb3b3",
      "40c1d5a4f9854259a906cb8b6339cda8",
      "db9eb79e6ee0485696cee9e855c1a052",
      "2d69357989f14d7db7623f72cae87875",
      "a3539104e4d14870be3ceb617099d15d",
      "0077eb2ea5f64e0e84f53f98462842b5"
     ]
    },
    "id": "9cz0ICwbmN5N",
    "outputId": "dd7a3c3e-fda3-436a-873e-7ec3d65b7cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274c0e74340045a881b4aa8d13b1e1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Preprocessing steps on the training/testing data. You can define your own data augmentation\n",
    "# here, and PyTorch's API will do the rest for you.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# This will automatically download the dataset for you if it cannot find the data in root\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5I4v9hH3mN5S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtml59LJmN5X"
   },
   "source": [
    "## 2.1 Simple NN\n",
    "Implement a simple feed-forward neural network, and train it on the CIFAR-10 training set. Here's some specific requirements:\n",
    "1. The network should only consists of `nn.Linear` layers and the activation functions of your choices (e.g. `nn.Tanh`, `nn.ReLU`, `nn.Sigmoid`, etc). \n",
    "2. Train your model with `torch.optim.SGD` with the hyperparameters you like the most. \n",
    "\n",
    "Note that the hyperparameters work in previous assignment might not work the same, as the implementations of layers could be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DA8f8r1mN5X"
   },
   "source": [
    "### 2.1.1 Design and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kPuGtu5LmN5Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Mefs_lnlmN5d"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct your small feedforward NN here.                                    #\n",
    "        ################################################################################\n",
    "        self.fc1 = nn.Linear(32*32*3, 1600) \n",
    "        self.fc2 = nn.Linear(1600, 800)\n",
    "        self.fc3 = nn.Linear(800, 10)\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # note that: here, the data is of the shape (B, C, H, W)\n",
    "        # where B is the batch size, C is color channels, and H\n",
    "        # and W is height and width.\n",
    "        # To feed it into the linear layer, we need to reshape it\n",
    "        # with .view() function.\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1) # reshape the data from (B, C, H, W) to (B, C*H*W)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass, output the prediction score.                                   #\n",
    "        ################################################################################\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        return x\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "il93hQ5AmN5i"
   },
   "outputs": [],
   "source": [
    "epoch = 2\n",
    "lr = 1e-2\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "net = SimpleNN()\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "DZgetUoNURAt",
    "outputId": "471d4038-11da-4134-aad4-8a7aa1d7e4d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.305\n",
      "[1,  4000] loss: 0.277\n",
      "[1,  6000] loss: 0.273\n",
      "[1,  8000] loss: 0.265\n",
      "[1, 10000] loss: 0.261\n",
      "[1, 12000] loss: 0.258\n",
      "[2,  2000] loss: 0.241\n",
      "[2,  4000] loss: 0.243\n",
      "[2,  6000] loss: 0.239\n",
      "[2,  8000] loss: 0.239\n",
      "[2, 10000] loss: 0.241\n",
      "[2, 12000] loss: 0.236\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 12000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jhZMLrnuZtJC",
    "outputId": "2f20b9c0-7a48-410e-af22-2b90a60ae17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AjTEBcRzZuNl",
    "outputId": "7fa6b731-8de3-46b6-8833-b25c397bdc66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7wgo9YzmN5o"
   },
   "source": [
    "Now evaluate your model with the helper function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf2SjvvRmN5u"
   },
   "source": [
    "### 2.1.2 Evaluate NN \n",
    "Evaluate your NN. You should get an accuracy around **50%** on training set and **49%** on testing set.\n",
    "\n",
    "Training - 53%  Testing - 48%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZXHXwKHmN5v"
   },
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "train_acc = get_model_acc(model, train_loader)\n",
    "test_acc = get_model_acc(model, test_loader)\n",
    "print(f'Training accuracy: {train_acc}, Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCPo7zIwmN5z"
   },
   "source": [
    "## 2.2 Convolutional Neural Network (CNN)\n",
    "Convolutional layer has been proven to be extremely useful for vision-based task. As mentioned in the lecture, this speical layer allows the model to learn filters that capture crucial visual features. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8oEn317mN50"
   },
   "source": [
    "### 2.2.1 Implement and Evaluate CNN \n",
    "In this section, you will need to construct a CNN for classifying CIFAR-10 image. Specifically, you need to:\n",
    "1. build a `CNNClassifier` with `nn.Conv2d`, `nn.Maxpool2d` and activation functions that you think are appropriate. \n",
    "2. You would need to flatten the output of your convolutional networks with `view()`, and feed it into a `nn.Linear` layer to predict the class labels of the input. \n",
    "\n",
    "Once you are done with your module, train it with `optim.SGD`, and evaluate it. You should get an accuracy around **55%** on training set and **53%** on testing set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pCvhva7vmN51"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "lAfIbDIb5ZCl"
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "       \n",
    "                                        nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "\n",
    "                                        nn.MaxPool2d(2,2),                    # (N,6,28,28) --> (N,6,14,14)               kernel_size=2,stride=2\n",
    "                                        nn.Conv2d(6,16,5), nn.ReLU(),                             # (N,6,14,14) --> (N,16,10,10)\n",
    "                                        nn.MaxPool2d(2,2))                                      #(N,16,10,10) --> (N,16,5,5)         kernel_size= 2,stride=2\n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(400,10))          #16*5*5 = 400 as input   in_features=400,out_features=120\n",
    "                                                        #output features = 10\n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "PgpkDVocmN5_"
   },
   "outputs": [],
   "source": [
    "# You can tune these hyperparameters as you like.\n",
    "num_epochs = 10\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zEeD4Ymf_DrQ",
    "outputId": "1df24e3d-f9b3-49e9-c658-c3b67272f1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 12000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "R-y9MiU2Xor6",
    "outputId": "d7a3d604-1b45-412c-8b01-5d5b2c70431e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 63 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Q6zglDUFXsCj",
    "outputId": "66a9543b-794b-4252-ecaa-625d7ccd0966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8v5MGo9emN6N"
   },
   "source": [
    "<span style=\"color:red\">**Explain your design and hyperparameter choice in three or four sentences:**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nn3CeRT0mVqG"
   },
   "outputs": [],
   "source": [
    "We get the test accuracy as 60 % and training accuracy as 63 %\n",
    "Conv, Relu, Pool is considered one set and repeated for the next layer.Filter increase the output channels which are halved by the maxpool.\n",
    "Conv1 - Relu - Max pool - Conv2 - Relu - Max pool -- Linear Layer (). \n",
    "The dimensions of each layer are commented with the two convolution layers consists of 6 size 5 filter in first and 16 filters in the second convolution layer, a lower learning rate 1e-3 gives better accuracy.A lower batch size resuted in faster training at a lower epoch\n",
    "Repeating this architecture for many CNN layers has been known to give better accuracy.(Source: Pytorch tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDaE2yaVmN6O"
   },
   "source": [
    "### 2.2.2 STACK MORE LAYERS\n",
    "Now, **try at least 4 network architectures with different numbers of convolutional layers**. Train these settings with `optim.SGD`, plot the training/testing accuracy as a fuction of convolutional layers and describe what you have observed (running time, performance, etc). **Please make sure your figures are with clear legends and labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V_IuaY2mN6O"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "# Using simular CNN architecture -() CNN- Relu - Maxpool)n - Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txKyH7dcoFiI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "070c2d910c5444bb88990e2945dbaaec",
      "bf6aeaadb59843b5a29c7818b0f921a4",
      "241f719b7ec94f66b6496b5ae77ed850",
      "06528836c93a401cb180a02b31359524",
      "73a8b59ff76e4d7983e364fec52eccd7",
      "9137101b317a4261bfcfad2e002ce41e",
      "ea7bba3d57504e63b137aab85816b4d5",
      "9f8e647ec1644becbdc843fbc86e3380"
     ]
    },
    "id": "jU-wLD7Yg56a",
    "outputId": "56993df4-e5df-4479-a79c-2a514bc5a321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070c2d910c5444bb88990e2945dbaaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Preprocessing steps on the training/testing data. You can define your own data augmentation\n",
    "# here, and PyTorch's API will do the rest for you.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# This will automatically download the dataset for you if it cannot find the data in root\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wg4iAf6OBF3j"
   },
   "outputs": [],
   "source": [
    "#1 Conv Layer\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "       \n",
    "                                        nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "\n",
    "                                        nn.MaxPool2d(2,2))                    # (N,6,28,28) --> (N,6,14,14)               kernel_size=2,stride=2\n",
    "                                        \n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        \n",
    "        self.dense_layer = nn.Sequential(nn.Linear(1176,10))          #6*14*14\n",
    "                                                  \n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "f7GSxtf2k91_"
   },
   "outputs": [],
   "source": [
    "# You can tune these hyperparameters as you like.\n",
    "num_epochs = 2\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGZsHQOVKh2q"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 12000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-XAdT3-wMGhv",
    "outputId": "e68719ee-f19f-4403-b135-eab8a0bee41f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fO5bj4oUMbkb",
    "outputId": "9a49c534-946c-4dce-ce09-03ed00c47b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 47 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81mZvX-wDSr9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kSZBb5RGCrRE"
   },
   "outputs": [],
   "source": [
    "#2 Conv Layer\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "       \n",
    "                                        nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "\n",
    "                                        nn.MaxPool2d(2,2),                    # (N,6,28,28) --> (N,6,14,14)               kernel_size=2,stride=2\n",
    "                                        nn.Conv2d(6,16,5), nn.ReLU(),                             # (N,6,14,14) --> (N,16,10,10)\n",
    "                                        nn.MaxPool2d(2,2))                                      #(N,16,10,10) --> (N,16,5,5)         kernel_size= 2,stride=2\n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(400,10))          #16*5*5 = 400 as input   in_features=400,out_features=120\n",
    "                                                         #output features = 10\n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "agISV8J7gmWP"
   },
   "outputs": [],
   "source": [
    "# You can tune these hyperparameters as you like.\n",
    "num_epochs = 2\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "Oi46NKxTNaYX",
    "outputId": "48146fcd-53f5-4627-a6e3-d893dc648b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.893\n",
      "[1,  4000] loss: 1.626\n",
      "[1,  6000] loss: 1.531\n",
      "[1,  8000] loss: 1.491\n",
      "[1, 10000] loss: 1.444\n",
      "[1, 12000] loss: 1.415\n",
      "[2,  2000] loss: 1.361\n",
      "[2,  4000] loss: 1.330\n",
      "[2,  6000] loss: 1.347\n",
      "[2,  8000] loss: 1.358\n",
      "[2, 10000] loss: 1.344\n",
      "[2, 12000] loss: 1.341\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HuAzzUuQWTOW",
    "outputId": "7114c5be-62d2-45a0-a088-ac6834f475c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Tz4LAiPKWWW_",
    "outputId": "3e20a581-31f8-44d9-990b-6f917133b015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "6GS21Kk4C1K5"
   },
   "outputs": [],
   "source": [
    "#3 Conv layer\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "       \n",
    "                                        nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "\n",
    "                                        nn.MaxPool2d(2,2),                    # (N,6,28,28) --> (N,6,14,14)               kernel_size=2,stride=2\n",
    "                                        nn.Conv2d(6,12,5), nn.ReLU(),                             # (N,6,14,14) --> (N,12,10,10)\n",
    "                                                                             \n",
    "                                        nn.Conv2d(12,24,5), nn.ReLU(),         #(N,12,10,10) --> (N,24,6,6)\n",
    "                                        nn.MaxPool2d(2,2))                     #(N,24,3,3)\n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(216,10))          #24*3*3 =  as input   \n",
    "                                         \n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) \n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "h8L2jEjt-D33"
   },
   "outputs": [],
   "source": [
    "# You can tune these hyperparameters as you like.\n",
    "num_epochs = 10\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cpspbr8r5nPH",
    "outputId": "6d0bc0ec-bc59-4e46-a0a5-af2250d888c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.876\n",
      "[1,  4000] loss: 1.638\n",
      "[1,  6000] loss: 1.522\n",
      "[1,  8000] loss: 1.472\n",
      "[1, 10000] loss: 1.472\n",
      "[1, 12000] loss: 1.448\n",
      "[2,  2000] loss: 1.389\n",
      "[2,  4000] loss: 1.369\n",
      "[2,  6000] loss: 1.349\n",
      "[2,  8000] loss: 1.373\n",
      "[2, 10000] loss: 1.367\n",
      "[2, 12000] loss: 1.337\n",
      "[3,  2000] loss: 1.284\n",
      "[3,  4000] loss: 1.298\n",
      "[3,  6000] loss: 1.307\n",
      "[3,  8000] loss: 1.313\n",
      "[3, 10000] loss: 1.313\n",
      "[3, 12000] loss: 1.289\n",
      "[4,  2000] loss: 1.267\n",
      "[4,  4000] loss: 1.241\n",
      "[4,  6000] loss: 1.261\n",
      "[4,  8000] loss: 1.291\n",
      "[4, 10000] loss: 1.274\n",
      "[4, 12000] loss: 1.263\n",
      "[5,  2000] loss: 1.234\n",
      "[5,  4000] loss: 1.245\n",
      "[5,  6000] loss: 1.271\n",
      "[5,  8000] loss: 1.273\n",
      "[5, 10000] loss: 1.256\n",
      "[5, 12000] loss: 1.256\n",
      "[6,  2000] loss: 1.213\n",
      "[6,  4000] loss: 1.220\n",
      "[6,  6000] loss: 1.226\n",
      "[6,  8000] loss: 1.274\n",
      "[6, 10000] loss: 1.245\n",
      "[6, 12000] loss: 1.243\n",
      "[7,  2000] loss: 1.201\n",
      "[7,  4000] loss: 1.244\n",
      "[7,  6000] loss: 1.239\n",
      "[7,  8000] loss: 1.245\n",
      "[7, 10000] loss: 1.220\n",
      "[7, 12000] loss: 1.238\n",
      "[8,  2000] loss: 1.218\n",
      "[8,  4000] loss: 1.204\n",
      "[8,  6000] loss: 1.244\n",
      "[8,  8000] loss: 1.239\n",
      "[8, 10000] loss: 1.223\n",
      "[8, 12000] loss: 1.245\n",
      "[9,  2000] loss: 1.182\n",
      "[9,  4000] loss: 1.224\n",
      "[9,  6000] loss: 1.210\n",
      "[9,  8000] loss: 1.225\n",
      "[9, 10000] loss: 1.221\n",
      "[9, 12000] loss: 1.267\n",
      "[10,  2000] loss: 1.179\n",
      "[10,  4000] loss: 1.219\n",
      "[10,  6000] loss: 1.206\n",
      "[10,  8000] loss: 1.211\n",
      "[10, 10000] loss: 1.230\n",
      "[10, 12000] loss: 1.220\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1bgj3NYG9q30",
    "outputId": "15c43e0a-8e94-4374-fe60-b2571464e232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 60 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "gBHMDdtWKWsb",
    "outputId": "1f16a498-ccaf-46af-8378-ec51e7ad3921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "38N3033EC6FV"
   },
   "outputs": [],
   "source": [
    "# 4 Conv Layer\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "                                               nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "                                     \n",
    "                                        nn.Conv2d(6,12,5), nn.ReLU(),                             # (N,6,28,28) --> (N,12,24,24)\n",
    "                                        nn.MaxPool2d(2,2),                                         # (N,12,24,24) --> (N,12,12,12)\n",
    "                                                                             \n",
    "                                        nn.Conv2d(12,24,5), nn.ReLU(),         #(N,12,12,12) --> (N,24,8,8)\n",
    "                                        nn.Conv2d(24,48,5), nn.ReLU(),         #  (N,24,8,8)  --> (N,48,4,4) \n",
    "                                        nn.MaxPool2d(2,2))                     #(N,48,4,4) --> (N,48,2,2)\n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(192,10))          #24*3*3 =  as input   \n",
    "                                         \n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) \n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "OY5WnDsu9-HB"
   },
   "outputs": [],
   "source": [
    "# You can tune these hyperparameters as you like.\n",
    "num_epochs = 10\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6k5-EfiXLTgB",
    "outputId": "307b63df-fcb0-4462-e25d-2d8c52db6974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.062\n",
      "[1,  4000] loss: 1.766\n",
      "[1,  6000] loss: 1.664\n",
      "[1,  8000] loss: 1.565\n",
      "[1, 10000] loss: 1.517\n",
      "[1, 12000] loss: 1.470\n",
      "[2,  2000] loss: 1.395\n",
      "[2,  4000] loss: 1.357\n",
      "[2,  6000] loss: 1.346\n",
      "[2,  8000] loss: 1.326\n",
      "[2, 10000] loss: 1.307\n",
      "[2, 12000] loss: 1.302\n",
      "[3,  2000] loss: 1.203\n",
      "[3,  4000] loss: 1.238\n",
      "[3,  6000] loss: 1.250\n",
      "[3,  8000] loss: 1.200\n",
      "[3, 10000] loss: 1.218\n",
      "[3, 12000] loss: 1.208\n",
      "[4,  2000] loss: 1.152\n",
      "[4,  4000] loss: 1.129\n",
      "[4,  6000] loss: 1.156\n",
      "[4,  8000] loss: 1.167\n",
      "[4, 10000] loss: 1.161\n",
      "[4, 12000] loss: 1.147\n",
      "[5,  2000] loss: 1.075\n",
      "[5,  4000] loss: 1.111\n",
      "[5,  6000] loss: 1.129\n",
      "[5,  8000] loss: 1.123\n",
      "[5, 10000] loss: 1.134\n",
      "[5, 12000] loss: 1.115\n",
      "[6,  2000] loss: 1.043\n",
      "[6,  4000] loss: 1.086\n",
      "[6,  6000] loss: 1.094\n",
      "[6,  8000] loss: 1.069\n",
      "[6, 10000] loss: 1.102\n",
      "[6, 12000] loss: 1.093\n",
      "[7,  2000] loss: 1.024\n",
      "[7,  4000] loss: 1.047\n",
      "[7,  6000] loss: 1.055\n",
      "[7,  8000] loss: 1.066\n",
      "[7, 10000] loss: 1.088\n",
      "[7, 12000] loss: 1.072\n",
      "[8,  2000] loss: 1.008\n",
      "[8,  4000] loss: 1.045\n",
      "[8,  6000] loss: 1.047\n",
      "[8,  8000] loss: 1.040\n",
      "[8, 10000] loss: 1.065\n",
      "[8, 12000] loss: 1.076\n",
      "[9,  2000] loss: 1.006\n",
      "[9,  4000] loss: 1.022\n",
      "[9,  6000] loss: 1.034\n",
      "[9,  8000] loss: 1.034\n",
      "[9, 10000] loss: 1.052\n",
      "[9, 12000] loss: 1.079\n",
      "[10,  2000] loss: 1.012\n",
      "[10,  4000] loss: 1.002\n",
      "[10,  6000] loss: 1.028\n",
      "[10,  8000] loss: 1.039\n",
      "[10, 10000] loss: 1.052\n",
      "[10, 12000] loss: 1.056\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "E1-OBG9hU4_U",
    "outputId": "4146001d-c13f-400a-e308-4236cc4eb1af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 61 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "gNQqaeVDaIh9",
    "outputId": "72d09eaf-1eca-4426-efdc-9683b8846f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "-6AdtbSFbyIV",
    "outputId": "814144d9-931f-414f-8e61-94c48d5eedcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb03da706d8>"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "n_layer = [1, 2, 3, 4]   #Number of CNN layers\n",
    "acc_trg = [52,55,60,61]\n",
    "\n",
    "acc_test = [47,54,56,56]\n",
    "\n",
    "plt.plot(n_layer,acc_trg)\n",
    "plt.plot(n_layer,acc_test)\n",
    "\n",
    "plt.xlabel('Number of CNN layers')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend(['Training Accuracy', 'Testing Accuracy'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "190187gimN6T"
   },
   "source": [
    "<span style=\"color:red\">****</span>\n",
    "Stacking layers after acertain point leads to overfitting without regularization like drop out.The test accuracy increases with each layers but the difference between test and train acccuracy starts increasing with each layer due to overfitting without regularization.Also running time increases with each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVFyvGewmN6T"
   },
   "source": [
    "### 2.2.3 Optimizer? Optimizer! \n",
    "So far, we only use SGD as our optimizer. Now, pick two other optimizers, train your favorite CNN models, and compare the performance you get. What did you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvM_VxulmN6T"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "O5eyc0uUV8NG"
   },
   "outputs": [],
   "source": [
    "#2 Conv Layer\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "       \n",
    "                                        nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "\n",
    "                                        nn.MaxPool2d(2,2),                    # (N,6,28,28) --> (N,6,14,14)               kernel_size=2,stride=2\n",
    "                                        nn.Conv2d(6,16,5), nn.ReLU(),                             # (N,6,14,14) --> (N,16,10,10)\n",
    "                                        nn.MaxPool2d(2,2))                                      #(N,16,10,10) --> (N,16,5,5)         kernel_size= 2,stride=2\n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(400,10))          #16*5*5 = 400 as input   in_features=400,out_features=120\n",
    "                                         #nn.ReLU(),\n",
    "                                         #nn.Linear(120,84),                       #Dense Layer 1: 120 Neurons\n",
    "                                         #nn.ReLU(),\n",
    "                                         #nn.Linear(84,10))                   #output features = 10\n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "4R09hRXbSVE8"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssr4JiNiWTat"
   },
   "outputs": [],
   "source": [
    "#Adam optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AlQxvibSrfai",
    "outputId": "be2be782-e975-4e66-e088-9480a048465e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MpASl4F8rfxf",
    "outputId": "efe7a150-c9d2-46b3-d6c4-8d14bfb3629f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JURjT7e2rf16",
    "outputId": "9bf735c0-d309-419a-dc31-50c625e0ec12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msYouKOYWUop"
   },
   "outputs": [],
   "source": [
    "#RMSprop optimizer\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JCNl9tf6Je_B",
    "outputId": "04bf8de6-a487-45f3-b768-1545d795eaab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "oCbuy9ReJw3J",
    "outputId": "261872ba-f847-434f-8d37-a6527b68f0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 65 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ZfPACAaKM1P5",
    "outputId": "67247455-8777-418b-d9c1-9a1fd9eb0f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nwz2qCjwmQph"
   },
   "outputs": [],
   "source": [
    "Test accuracy - Adam = 56, RMS PRop = 60\n",
    " \n",
    "\n",
    "RMSProp optimizer performs better than Adams prop Keeping other hyparameters parameters same like the number of layer learning rate, epoch, batch size etc., although it takes longer tiem to train using Admas prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHPTN-dmN6W"
   },
   "source": [
    "### 2.2.4 Improve Your Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJKeJw2QmN6X"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sf6K-sG_-1v-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "0e854ae68108413bb5e8dab719725b83",
      "fd60f39a5f4847c2afcbf399828a0a7e",
      "537fa4f7f050452e88e342cdfbaaf90b",
      "a9eef87baec4455ab241df82e3ea9214",
      "c006b1e7bbc04b5f8799ca680c17b69b",
      "d80fa5f926b745aea6c8d35ddaa49e49",
      "522837d8b4ff4df0ad8598073248836a",
      "1aaad0cb677e442c81479624db153065"
     ]
    },
    "id": "d2pLnJ3vFEu9",
    "outputId": "25cad483-dc07-4950-c9d9-4c537931d124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e854ae68108413bb5e8dab719725b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Preprocessing steps on the training/testing data. You can define your own data augmentation\n",
    "# here, and PyTorch's API will do the rest for you.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# This will automatically download the dataset for you if it cannot find the data in root\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-c_DzfcH0kE"
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size,padding)   the input channel size of CIFAR 10 data is 3\n",
    "         #BatchNorm2d(number of channels)\n",
    "         #Maxpool2D(kernel size, stride)\n",
    "          #nn.Dropout2d(p)\n",
    "        self.conv_model = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "                                        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "                                        nn.BatchNorm2d(32),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            # Conv Layer block 2\n",
    "                                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "                                        nn.Dropout2d(p=0.05),\n",
    "\n",
    "                                        # Conv Layer block 3\n",
    "                                        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.BatchNorm2d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2, 2)) # output: 256 x 4 x 4  \n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(\n",
    "                                          nn.Dropout(p=0.1),\n",
    "                                          nn.Linear(4096, 1024),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Linear(1024, 512),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Dropout(p=0.1),\n",
    "                                          nn.Linear(512, 10))\n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n",
    "        #y = y.view(y.size(o),-1)\n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q6ut_VQJ1emJ"
   },
   "outputs": [],
   "source": [
    "# 4 Conv Layer\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Construct a CNN with 2 or 3 convolutional layers and 1 linear layer for      #\n",
    "        # outputing class prediction. You are free to pick the hyperparameters         #\n",
    "        ################################################################################\n",
    "         # conv2d(no of input channels,number of output channels, kernel size)   the input channel size of CIFAR 10 data is 3\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(3,6,5),       # (N,3,32,32) --> (N,6,28,28) in_channels=3,out_channels=6,kernel_size=5\n",
    "                                        nn.ReLU(),                                                 # Relu --> Activation Function\n",
    "                                        nn.BatchNorm2d(6),\n",
    "                                        nn.Conv2d(6,12,5), \n",
    "                                        nn.ReLU(),                             # (N,6,28,28) --> (N,12,24,24)\n",
    "                                        nn.MaxPool2d(2,2),                                         # (N,12,24,24) --> (N,12,12,12)\n",
    "                                        nn.Dropout2d(p=0.05),\n",
    "                                        nn.Dropout2d(p=0.05),\n",
    "                                        nn.Conv2d(12,24,5),                    #(N,12,12,12) --> (N,24,8,8)\n",
    "                                        nn.BatchNorm2d(24),\n",
    "                                        nn.ReLU(),         \n",
    "                                        nn.Conv2d(24,48,5), nn.ReLU(),         #  (N,24,8,8)  --> (N,48,4,4) \n",
    "                                        nn.MaxPool2d(2,2))                     #(N,48,4,4) --> (N,48,2,2)\n",
    "\n",
    "\n",
    "#Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(192,10))\n",
    "                                         #nn.Dropout2d(p=0.1),\n",
    "                                         #nn.ReLU(),                       #24*3*3 =  as input   \n",
    "                                         #nn.Linear(80,40),\n",
    "                                         #nn.ReLU(),\n",
    "                                         #nn.Linear(40,10))\n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Forward pass of your network. First extract feature with CNN, and predict    #\n",
    "        # class scores with linear layer. Be careful about your input/output shape.    #\n",
    "        ################################################################################\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) \n",
    "        y = self.dense_layer(y)\n",
    "        return y\n",
    "    \n",
    "net = CNNClassifier()\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KX0bFHTo--jH"
   },
   "outputs": [],
   "source": [
    "# You can tune these hyperparameters as you like.\n",
    "num_epochs = 20\n",
    "lr = 1e-1\n",
    "n_input = 3072\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Your training code here.                                                     #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AyPiKFmCA3ty",
    "outputId": "f6960730-ec25-4261-9f58-942cbc538c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qEnfoxIi_-VL",
    "outputId": "1768e4ce-a560-45d8-c187-2212a83906a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ehkm09h6ABTq",
    "outputId": "8b649e65-89cb-422b-a0fb-0566179f3d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 64 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoIQ-TDcDdls"
   },
   "source": [
    "Used Batch Norm and Drop out on the 4 CNN layers\n",
    "Note: Did not include the code with more layers of CNN since it was taking too long to train, also used lower epochs due to time constraint"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YcsJ2yuwmN4V",
    "nxDE84vqmN43",
    "Wf2SjvvRmN5u"
   ],
   "name": "Copy of DL_Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0077eb2ea5f64e0e84f53f98462842b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06528836c93a401cb180a02b31359524": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f8e647ec1644becbdc843fbc86e3380",
      "placeholder": "​",
      "style": "IPY_MODEL_ea7bba3d57504e63b137aab85816b4d5",
      "value": " 170500096/? [00:20&lt;00:00, 72578785.65it/s]"
     }
    },
    "070c2d910c5444bb88990e2945dbaaec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_241f719b7ec94f66b6496b5ae77ed850",
       "IPY_MODEL_06528836c93a401cb180a02b31359524"
      ],
      "layout": "IPY_MODEL_bf6aeaadb59843b5a29c7818b0f921a4"
     }
    },
    "0e854ae68108413bb5e8dab719725b83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_537fa4f7f050452e88e342cdfbaaf90b",
       "IPY_MODEL_a9eef87baec4455ab241df82e3ea9214"
      ],
      "layout": "IPY_MODEL_fd60f39a5f4847c2afcbf399828a0a7e"
     }
    },
    "1aaad0cb677e442c81479624db153065": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "241f719b7ec94f66b6496b5ae77ed850": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9137101b317a4261bfcfad2e002ce41e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73a8b59ff76e4d7983e364fec52eccd7",
      "value": 1
     }
    },
    "274c0e74340045a881b4aa8d13b1e1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca16990a99cb445fbf35b516d9deb3b3",
       "IPY_MODEL_40c1d5a4f9854259a906cb8b6339cda8"
      ],
      "layout": "IPY_MODEL_bb452709a08843919787948ab5171fc0"
     }
    },
    "2d69357989f14d7db7623f72cae87875": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c1d5a4f9854259a906cb8b6339cda8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0077eb2ea5f64e0e84f53f98462842b5",
      "placeholder": "​",
      "style": "IPY_MODEL_a3539104e4d14870be3ceb617099d15d",
      "value": " 170500096/? [00:30&lt;00:00, 17409172.45it/s]"
     }
    },
    "522837d8b4ff4df0ad8598073248836a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "537fa4f7f050452e88e342cdfbaaf90b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d80fa5f926b745aea6c8d35ddaa49e49",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c006b1e7bbc04b5f8799ca680c17b69b",
      "value": 1
     }
    },
    "73a8b59ff76e4d7983e364fec52eccd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9137101b317a4261bfcfad2e002ce41e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f8e647ec1644becbdc843fbc86e3380": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3539104e4d14870be3ceb617099d15d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9eef87baec4455ab241df82e3ea9214": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1aaad0cb677e442c81479624db153065",
      "placeholder": "​",
      "style": "IPY_MODEL_522837d8b4ff4df0ad8598073248836a",
      "value": " 170500096/? [00:30&lt;00:00, 16659419.42it/s]"
     }
    },
    "bb452709a08843919787948ab5171fc0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf6aeaadb59843b5a29c7818b0f921a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c006b1e7bbc04b5f8799ca680c17b69b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ca16990a99cb445fbf35b516d9deb3b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d69357989f14d7db7623f72cae87875",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db9eb79e6ee0485696cee9e855c1a052",
      "value": 1
     }
    },
    "d80fa5f926b745aea6c8d35ddaa49e49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db9eb79e6ee0485696cee9e855c1a052": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ea7bba3d57504e63b137aab85816b4d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd60f39a5f4847c2afcbf399828a0a7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
